### **性能测试实战：混合场景与稳定性测试详解**

#### **一、性能测试场景实战回顾**

**1. 单接口基准测试（已完成）**

* **目的**：寻找单个接口的性能拐点（最佳并发 & 最大TPS）。

* **策略**：从小并发（如10）开始，逐步增压（10→20→50→100...），观察TPS和响应时间的变化趋势。

* **停止标志**：当TPS增长趋于平缓（或下降），而响应时间开始显著增加时，即找到**性能拐点**。

* **示例数据（用户列表接口）**：

  | 并发数 | 持续时间(s) | **TPS**     | 平均响应时间(ms) | 结论                                |
  | :----- | :---------- | :---------- | :--------------- | :---------------------------------- |
  | 100    | 30          | **1487**    | 65               | **最佳并发点**（TPS高，延迟可接受） |
  | 200    | 30          | 1600 (波动) | 120              | TPS增长有限，延迟大幅增加           |
  | 300    | 30          | ~1400       | 202              | TPS未显著提升，延迟剧增             |

#### **二、混合场景负载测试**

**1. 核心目的**
模拟真实生产环境，验证**多个不同业务接口同时运行时的系统综合性能**。因为不同业务可能竞争系统资源（CPU、内存、数据库连接等），单独测试性能良好的接口，在混合场景下可能出现性能劣化。

**2. 关键要素：业务比例**

*   **来源**：生产环境的**业务监控数据**（如通过APM工具、日志分析得出）。例如，一天中“登录”、“浏览商品”、“下单”的调用次数比例约为 `8:20:1`。
*   **意义**：按照真实业务流量比例分配压力，测试结果更具代表性和参考价值。

**3. 实施步骤**
    1.  **确定接口与比例**：例如，测试“用户列表”（接口A）和“用户登录”（接口B），假设生产比例为 `2:8`。
    2.  **设计JMeter脚本**：
        *   创建**两个独立的线程组**（Thread Group A 和 B）。
        *   每个线程组内放置对应的接口请求。
        *   **按比例设置各线程组的并发数**。
    3.  **配置并发参数化（推荐）**：
        *   为每个线程组的并发数使用 `${__P(参数名)}` 函数。
        *   例如：线程组A: `${__P(threadsA, 2)}`，线程组B: `${__P(threadsB, 8)}`。
    4.  **执行与记录**：
        *   通过命令行传递比例参数并执行：`jmeter ... -JthreadsA=2 -JthreadsB=8 -l mix_10.jtl`
        *   **关注核心指标是总TPS**（即两个线程组产生的总吞吐量）。
        *   记录不同总并发下的性能数据，寻找混合场景的**综合性能拐点**。

**4. 与顺序流程测试的区别**

| 测试类型         | 线程组设计     | 接口关系                                       | 并发比例                    |
| :--------------- | :------------- | :--------------------------------------------- | :-------------------------- |
| **混合场景测试** | 多个独立线程组 | 业务独立，**无强顺序依赖**                     | 按**生产业务比例**设置      |
| **顺序流程测试** | 单个线程组     | **有强业务顺序和数据依赖**（如登录→下单→支付） | **固定为1:1**，无需设置比例 |

#### **三、稳定性/耐力测试**

**1. 核心目的**
验证系统在**长时间（如12/24小时）持续压力下**，是否会出现性能衰减、内存泄漏、资源耗尽等问题。

**2. 关键实施要点**
    *   **压力水平**：通常使用**单接口或混合场景中找到的“最佳并发数”**，或者**预估日常平均压力的80%-100%**。
    *   **持续时间**：**长周期**，如8小时、12小时、24小时。
    *   **监控重点**：
        *   **性能趋势**：TPS、响应时间是否保持平稳，有无逐渐下降趋势。
        *   **资源泄漏**：内存使用率是否随时间持续上涨（内存泄漏迹象）。
        *   **错误率**：是否在长时间运行后错误率开始升高。
    *   **报告分析**：**必须生成HTML报告**，通过其中的 **Over Time（随时间变化）图表**（特别是TPS、响应时间趋势图），直观判断系统在长时间运行下的稳定性。

#### **四、性能测试报告编写建议**

在最终的性能测试报告中，关于性能拐点的数据呈现应做到**清晰、有说服力**。

* **数据选择**：无需罗列所有测试数据，应精选能**清晰展示拐点趋势的5组左右数据**。

* **推荐结构**：

  1.  **拐点前2组数据**（显示TPS快速增长，响应时间平稳）。
  2.  **拐点本身数据**（显示TPS达到峰值，响应时间开始明显增加）。
  3.  **拐点后2组数据**（显示TPS增长停滞或下降，响应时间大幅攀升）。

* **示例格式**：

  > **用户列表接口性能拐点分析**  
  > 测试表明，当并发用户数达到 **100** 时，系统吞吐量（TPS）达到最佳值 **~1500**，平均响应时间为 **65ms**。此后继续增加并发，TPS增长有限（如200并发时约1600），但平均响应时间显著恶化至 **120ms+**。因此，确定该接口的**最佳并发数为100**，**最大处理能力约为1500 TPS**。

#### **五、总结与行动建议**

1.  **完整性能评估流程**：**单接口基准测试 → 混合场景负载测试 → 稳定性耐力测试**。这是一个由点及面、由短及长的完整评估链条。
2.  **策略核心**：始终遵循 **“逐步增压，寻找拐点”** 的策略，并根据测试过程中TPS的增长幅度**灵活调整加压步长**。
3.  **工具熟练度**：掌握JMeter的**命令行参数化**（`-J` 参数与 `${__P()}` 函数）是提升测试效率的关键。
4.  **动手实践**：**理论知识必须通过实践巩固**。请务必课后寻找接口，完整走一遍单接口找拐点、配置混合场景、尝试长时间运行的流程。只有亲手操作，才能深刻理解细节（如脚本配置、结果分析、问题排查），并积累真正的“项目经验”，以应对未来的面试和工作挑战。

**最终目标**：通过系统化的性能测试，不仅能回答“系统能跑多快”（TPS），还能回答“系统能承受多少用户”（并发），以及“系统能否持续稳定运行”（稳定性），从而为系统优化、容量规划和架构决策提供坚实的数据支撑。